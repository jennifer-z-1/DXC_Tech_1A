{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a58999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cohere -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc46ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cohere hnswlib unstructured -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760ed5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98c7d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Obtaining dependency information for PyMuPDF from https://files.pythonhosted.org/packages/30/3f/356a70c105d4410c29529f1ca8c53b5d176b448a4409238b4dcd133507a4/PyMuPDF-1.24.10-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading PyMuPDF-1.24.10-cp311-none-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.24.10 (from PyMuPDF)\n",
      "  Obtaining dependency information for PyMuPDFb==1.24.10 from https://files.pythonhosted.org/packages/70/cb/8459d6c179befd7c6eee555334f054e9a6dcdd9f8671891e1da19e0ce526/PyMuPDFb-1.24.10-py3-none-win_amd64.whl.metadata\n",
      "  Downloading PyMuPDFb-1.24.10-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Downloading PyMuPDF-1.24.10-cp311-none-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.2 MB 320.0 kB/s eta 0:00:10\n",
      "   ---------------------------------------- 0.0/3.2 MB 325.1 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.1/3.2 MB 465.5 kB/s eta 0:00:07\n",
      "    --------------------------------------- 0.1/3.2 MB 465.5 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.1/3.2 MB 502.0 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.2/3.2 MB 784.3 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.3/3.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.4/3.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.5/3.2 MB 1.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.6/3.2 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.9/3.2 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.9/3.2 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.1/3.2 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.4/3.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.6/3.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.9/3.2 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.2/3.2 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.7/3.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.9/3.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.2/3.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading PyMuPDFb-1.24.10-py3-none-win_amd64.whl (13.2 MB)\n",
      "   ---------------------------------------- 0.0/13.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.2 MB 15.2 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/13.2 MB 10.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.2/13.2 MB 10.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.7/13.2 MB 10.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.2/13.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.3/13.2 MB 10.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.0/13.2 MB 10.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.6/13.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.9/13.2 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.1/13.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.4/13.2 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.5/13.2 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.6/13.2 MB 8.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.8/13.2 MB 8.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.1/13.2 MB 7.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.3/13.2 MB 7.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.8/13.2 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.4/13.2 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.0/13.2 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.6/13.2 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.3/13.2 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.9/13.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.7/13.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.5/13.2 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.2/13.2 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.4/13.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.1/13.2 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.2/13.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.2/13.2 MB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDFb, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.10 PyMuPDFb-1.24.10\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee09dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(\"API Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efd6ec9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIEFING\n",
      "EU Legislation in Progress\n",
      "Artificial intelligence act\n",
      "OVERVIEW\n",
      "European Union lawmakers signed the artificial intelligence (AI) act in June 2024. The AI act, the first\n",
      "binding worldwide horizontal regulation on AI, sets a common framework for the use and supply of\n",
      "AI systems in the EU.\n",
      "The new act offers a classification for AI systems with different requirements and obligations tailored\n",
      "to a 'risk-based approach'. Some AI systems presenting 'unacceptable' risks are prohibited. A wide\n",
      "range of 'high-risk' AI systems that can have a detrimental impact on people's health, safety or on\n",
      "their fundamental rights are authorised, but subject to a set of requirements and obligations to gain\n",
      "access to the EU market. AI systems posing limited risks because of their lack of transparency will\n",
      "be subject to information and transparency requirements, while AI systems presenting only minimal\n",
      "risk for people will not be subject to further obligations.\n",
      "The regulation also lays down specific rules for general purpose AI (GPAI) models and lays down\n",
      "more stringent requirements for GPAI models with 'high-impact capabilities' that could pose a\n",
      "systemic risk and have a significant impact on the internal market.\n",
      "The AI Act was published in the EU's Official Journal on 12 July 2024. It entered into force in August 2024.\n",
      "Proposal for a regulation of the European Parliament and of the Council laying down harmonised\n",
      "rules on artificial intelligence (artificial intelligence act) and amending certain Union legislative acts\n",
      "Committees Internal Market and Consumer Protection (IMCO) and COM(2021)206\n",
      "responsible: Civil Liberties, Justice and Home Affairs (LIBE) 21.4.2021\n",
      "(jointly under Rule 58) 2021/0106(COD)\n",
      "Rapporteurs: Brando Benifei (S&D, Italy) and Dragoş Tudorache\n",
      "(Renew, Romania)\n",
      "Ordinary legislative\n",
      "Shadow rapporteurs: Deirdre Clune, Axel Voss (EPP); Petar Vitanov (S&D);\n",
      "procedure (COD)\n",
      "Svenja Hahn, (Renew); Sergey Lagodinsky,\n",
      "(Parliament and\n",
      "Kim Van Sparrentak (Greens/EFA); Rob Rooken,\n",
      "Council on equal\n",
      "Kosma Złotowski (ECR); Jean-Lin Lacapelle, Jaak\n",
      "footing – formerly\n",
      "Madison (ID); Cornelia Ernst, Kateřina Konecna (The\n",
      "'co-decision')\n",
      "Left)\n",
      "Procedure Regulation (EU) 2024/1689\n",
      "completed. OJ L, 2024/1689, 12.7.2024\n",
      "EPRS | European Parliamentary Research Service\n",
      "Author: Tambiama Madiega\n",
      "Members' Research Service\n",
      "EN\n",
      "PE 698.792 – September 2024\n",
      "EPRS | European Parliamentary Research Service\n",
      "Introduction\n",
      "AI technologies are expected to bring a wide array of economic and societal benefits to a wide\n",
      "range of sectors, including environment and health, the public sector, finance, mobility, home affairs\n",
      "and agriculture. They are particularly useful for improving prediction, for optimising operations and\n",
      "resource allocation, and for personalising services.1 However, the implications of AI systems for\n",
      "fundamental rights protected under the EU Charter of Fundamental Rights, as well as the safety\n",
      "risks for users when AI technologies are embedded in products and services, are raising concern.\n",
      "Most notably, AI systems may jeopardise fundamental rights such as the right to non-discrimination,\n",
      "freedom of expression, human dignity, personal data protection and privacy.2\n",
      "Given the fast development of these technologies, in recent years AI regulation has become a central\n",
      "policy question in the European Union (EU). Policy-makers pledged to develop a 'human-centric'\n",
      "approach to AI to ensure that Europeans can benefit from new technologies developed and\n",
      "functioning according to the EU's values and principles. In its 2020 White Paper on Artificial\n",
      "Intelligence, the European Commission committed to promote the uptake of AI and address the\n",
      "risks associated with certain uses of this new technology. After having initially adopted a soft-law\n",
      "approach with the publication of its non-binding 2019 Ethics Guidelines for Trustworthy AI and\n",
      "Policy and investment recommendations, the European Commission shifted towards a legislative\n",
      "approach, calling for the adoption of harmonised rules for the development, placing on the market\n",
      "and use of AI systems.\n",
      "Leading the EU-level debate, the Parliament called on the Commission to assess the impact of AI\n",
      "and to draft an EU framework for AI, in its wide-ranging 2017 recommendations on civil law rules on\n",
      "robotics. In 2020 and 2021, Parliament adopted a number of non-legislative resolutions calling for\n",
      "EU action,3 as well as two legislative resolutions asking the Commission to establish a legal\n",
      "framework of ethical principles for the development, deployment and use of AI, robotics and related\n",
      "technologies in the Union and harmonising the legal framework for civil liability claims and imposition\n",
      "of a regime of strict liability on operators of high-risk AI systems.\n",
      "In the past, the Council has repeatedly called for the adoption of common AI rules, including in 2017\n",
      "and 2019. In 2020, the Council called upon the Commission to put forward concrete proposals that\n",
      "take existing legislation into account and follow a risk-based, proportionate and, if necessary,\n",
      "regulatory approach.\n",
      "The Commission launched a broad public consultation in 2020 and published an Impact Assessment\n",
      "of the regulation on artificial intelligence, a supporting study and a draft proposal, which received\n",
      "feedback from stakeholders.4 In its impact assessment, the Commission identified several problems\n",
      "raised by the development and use of AI systems, due to their specific characteristics, namely:\n",
      "(i) opacity (limited ability of the human mind to understand how certain AI systems operate),\n",
      "(ii) complexity, (iii) continuous adaptation and unpredictability, (iv) autonomous behaviour, and\n",
      "(v) functional dependence on data and on the quality of data.\n",
      "An increasing number of countries worldwide are designing and implementing AI governance legislation and\n",
      "policies. While the United States (US) had initially taken a lenient approach towards AI, calls for regulation\n",
      "have recently been mounting. The White House has released the Blueprint for an AI Bill of Rights, a set of\n",
      "guidelines to protect the rights of the American public in the age of AI and President Joe Biden signed an\n",
      "executive order on AI in 2023. Chinese government agencies approved some guidelines on generative AI, while\n",
      "the UK has announced a pro-innovation approach to AI regulation, which largely regulates AI via existing laws.\n",
      "At international level, the Organisation for Economic Co-operation and Development (OECD) adopted some\n",
      "non-binding Principles on AI, in 2019, UNESCO embraced a set of Recommendations on the Ethics of AI in\n",
      "2021, the G7 agreed some International Guiding Principles on Artificial Intelligence in 2023 and the Council of\n",
      "Europe adopted an international convention on AI in May 2024. Furthermore, in the context of the newly\n",
      "established EU-US tech partnership (the Trade and Technology Council), the EU and the US are seeking to\n",
      "develop a mutual understanding on the principles underpinning trustworthy and responsible AI.\n",
      "2\n",
      "Artificial intelligence act\n",
      "The changes the proposal would bring\n",
      "The draft AI act was designed as a horizontal EU legislative instrument applicable to all AI systems\n",
      "placed on the market or used in the Union, based on Article 114 and Article 16 of the Treaty on the\n",
      "Functioning of the European Union (TFEU) following the logic of the new legislative framework\n",
      "(NLF), i.e. the EU's approach to ensuring a range of products comply with the applicable legislation\n",
      "when they are placed on the EU market through conformity assessments and the use of CE marking.\n",
      "The Commission proposed enshrining in EU law a legal definition of 'AI system' referring to a range\n",
      "of software-based technologies using specific techniques and approaches ('machine learning',\n",
      "'logic and knowledge-based' systems, and 'statistical' approaches) that could be complemented\n",
      "through the adoption of delegated acts to factor in technological developments.\n",
      "The Commission also proposed to adopt a risk-based approach whereby legal intervention was\n",
      "tailored to concrete level of risk. Four categories were identified.\n",
      "First, the draft act proposed to explicitly ban the following harmful AI practices that are considered\n",
      "a clear threat to people's safety, livelihoods and rights owing to the 'unacceptable risk' they create:\n",
      " AI systems that deploy harmful manipulative 'subliminal techniques';\n",
      " AI systems that exploit specific vulnerable groups (physical or mental disability);\n",
      " AI systems used by public authorities, or on their behalf, for social scoring purposes;\n",
      " 'Real-time' remote biometric identification systems in publicly accessible spaces for\n",
      "law enforcement purposes, except in a limited number of cases.5\n",
      "Second, the draft act proposed to regulate high-risk AI systems that create adverse impact on\n",
      "people's safety or their fundamental rights. The draft text distinguished between two categories of\n",
      "high-risk AI systems.\n",
      " Systems used as a safety component of a product or falling under EU health and safety\n",
      "harmonisation legislation (e.g. toys, aviation, cars, medical devices, lifts).\n",
      " Systems deployed in eight specific areas specified in Annex (e.g. law enforcement),\n",
      "which the Commission could update as necessary through delegated acts.\n",
      "Such high-risk AI systems would have to comply with a range of requirements, particularly on risk\n",
      "management, testing, technical robustness, data training and data governance, transparency,\n",
      "human oversight, and cybersecurity, before being placed on the market or put into service. AI\n",
      "systems that conform to new harmonised EU standards would benefit from a presumption of\n",
      "conformity with the draft AI act requirements.\n",
      "Third, AI systems presenting limited risk, such as systems that interact with humans (i.e. chatbots),\n",
      "emotion recognition systems, biometric categorisation systems, and AI systems that generate or\n",
      "manipulate image, audio or video content (i.e. deepfakes), would be subject to a limited set of\n",
      "transparency obligations.\n",
      "Finally, all other AI systems presenting only low or minimal risk could be developed and used in the\n",
      "EU without conforming to any additional legal obligations. However, the proposed AI act envisaged\n",
      "the creation of codes of conduct to encourage providers of non-high-risk AI systems to apply the\n",
      "mandatory requirements for high-risk AI systems voluntarily.\n",
      "The proposal required Member States to designate one or more competent authorities, including a\n",
      "national supervisory authority to be tasked with supervising the regulation's application and\n",
      "implementation. It proposed to establish a European Artificial Intelligence Board (composed of\n",
      "representatives from the Member States and the Commission) at EU level. National market\n",
      "surveillance authorities would assess operators' compliance with the obligations and requirements\n",
      "of high-risk AI systems. Administrative fines of varying scales, depending on the severity of the\n",
      "infringement, were set as sanctions for non-compliance with the AI act.\n",
      "3\n",
      "EPRS | European Parliamentary Research Service\n",
      "Some measures were tailored to foster investments. The Commission proposed that Member States,\n",
      "or the European Data Protection Supervisor, could establish a regulatory sandbox, i.e. a controlled\n",
      "environment that facilitates the development, testing and validation of innovative AI systems (for a\n",
      "limited period of time) before they are put on the market. Sandboxing would enable participants to\n",
      "use personal data to foster AI innovation, without prejudice to the GDPR requirements. Other\n",
      "proposed measures were tailored specifically to small-scale providers and start-ups.\n",
      "Advisory committees\n",
      "The European Economic and Social Committee and the European Committee of the Regions\n",
      "adopted their opinions in 2021 and in 2022, respectively.\n",
      "National parliaments\n",
      "The deadline for the submission of reasoned opinions on the grounds of subsidiarity was\n",
      "2 September 2021. Contributions were received from the Czech Chamber of Deputies and the Czech\n",
      "Senate, the Portuguese Parliament, the Polish Senate and the German Bundesrat.\n",
      "Stakeholder views6\n",
      "Definitions were a contentious point of discussion among stakeholders. The Big Data Value\n",
      "Association, an industry-driven international not–for-profit organisation, stressed that the\n",
      "definition of AI systems was quite broad and would cover far more than what is subjectively\n",
      "understood as AI, including the simplest search, sorting and routing algorithms, which would\n",
      "consequently be subject to new rules. Furthermore, they asked for clarification of how components\n",
      "of larger AI systems (such as pre-trained AI components from other manufacturers or components\n",
      "not released separately), should be treated. AmCham, the American Chamber of Commerce in the\n",
      "EU, suggested avoiding over-regulation by adopting a narrower definition of AI systems, focusing\n",
      "strictly on high-risk AI applications (and not extended to AI applications that are not high risk, or\n",
      "software in general).\n",
      "While they generally welcomed the proposed AI act's risk-based approach, some stakeholders\n",
      "supported wider prohibition and regulation of AI systems. Civil rights organisations called for a ban\n",
      "on indiscriminate or arbitrarily targeted use of biometrics in public or publicly accessible spaces, and\n",
      "for restrictions on the uses of AI systems, including for border control and predictive policing.\n",
      "The European Enterprises Alliance stressed that there was general uncertainty about the roles and\n",
      "responsibilities of the different actors in the AI value chain (developers, providers, and users of AI\n",
      "systems). This was particularly challenging for companies providing general purpose application\n",
      "programming interfaces or open-source AI models that are not specifically intended for high-risk\n",
      "AI systems but are nevertheless used by third parties in a manner that could be considered high-\n",
      "risk. They also called for 'high-risk' to be redefined, based on the measurable harm and potential\n",
      "impact. AlgorithmWatch underlined that the applicability of specific rules should not depend on the\n",
      "type of technology, but on the impact it has on individuals and society. They called for the new rules\n",
      "to be defined according to the impact of the AI systems and recommend that every operator should\n",
      "conduct an impact assessment that assesses the system's risk levels on a case-by-case basis.\n",
      "Climate Change AI called for climate change mitigation and adaptation to be taken into account in\n",
      "the classification rules for high-risk AI systems and impose environmental protection requirements.\n",
      "The European Consumer Organisation, BEUC, stressed that the proposal required substantial\n",
      "improvement to guarantee consumer protection. The organisation argued that the proposal should\n",
      "have a broader scope and impose basic principles and obligations (e.g. on fairness, accountability\n",
      "and transparency) upon all AI systems, as well as prohibiting more comprehensively harmful\n",
      "practices (such as private entities' use of social scoring and of remote biometric identification\n",
      "systems in public spaces). Furthermore, consumers should be granted a strong set of rights,\n",
      "effective remedies and redress mechanisms, including collective redress.\n",
      "4\n",
      "Artificial intelligence act\n",
      "There were opposing views on the impact of the proposed regulation on investment. A study by the\n",
      "Centre for Data Innovation (representing large online platforms) highlighted that the compliance\n",
      "costs incurred under the proposed AI act would likely provoke a chilling effect on investment in AI\n",
      "in Europe, and could particularly deter small and medium-sized enterprises (SMEs) from developing\n",
      "high-risk AI systems. According to the study, the AI act would cost the European economy\n",
      "€31 billion over the next five years and reduce AI investments by almost 20 %. However, such\n",
      "estimates of the compliance costs were challenged by the experts from the Centre for European\n",
      "Policy Studies, as well as by other economists. The European Digital SME Alliance warned against\n",
      "overly stringent conformity requirements, and asked for effective SME representation in the\n",
      "standards-setting procedures and for mandatory sandboxes in all EU Member States.\n",
      "Academic and other views\n",
      "While generally supporting the Commission's proposal, critics called for amendments, including\n",
      "revising the 'AI systems' definition, ensuring a better allocation of responsibility, strengthening\n",
      "enforcement mechanisms and fostering democratic participation.7 Among the main issues were:\n",
      "AI systems definition\n",
      "The legal definition of 'AI systems' contained in the proposed AI act has been heavily criticised.\n",
      "Smuha et al. warned the definition lacks clarity and may lead to legal uncertainty, especially for some\n",
      "systems that would not qualify as AI systems under the draft text, while their use may have an\n",
      "adverse impact on fundamental rights.8 To address this issue, the authors proposed to broaden the\n",
      "legislation's scope to include explicitly all computational systems used in the identified high-risk\n",
      "domains, regardless of whether they are considered to be AI. Ebers et al. consider that the scope of\n",
      "'AI systems' was overly broad, which may lead to legal uncertainty for developers, operators, and\n",
      "users of AI systems and ultimately to over-regulation.9 They called on EU law-makers to exempt AI\n",
      "systems developed and used for research purposes and open-source software (OSS) from\n",
      "regulation. Other commentators questioned whether the proposed definition of 'AI systems' is truly\n",
      "technology neutral as it refers primarily to 'software', omitting potential future AI developments.\n",
      "Risk-based approach\n",
      "Academics also called for amendments, warning that the risk-based approach proposed by the\n",
      "Commission would not ensure a high level of protection of fundamental rights. Smuha et al. argued\n",
      "that the proposal does not always accurately recognise the wrongs and harms associated with\n",
      "different kinds of AI systems and therefore does not appropriately allocate responsibility. Among\n",
      "other things, they recommended adding a procedure that enables the Commission to broaden the\n",
      "list of prohibited AI systems, and proposed banning existing manipulative AI systems (e.g.\n",
      "deepfakes), social scoring and some biometrics. Ebers et al. called for a more detailed classification\n",
      "of risks to facilitate industry self-assessment and support, as well as prohibiting more AI systems\n",
      "(e.g. biometrics), including in the context of private use. Furthermore, some highlighted that the\n",
      "draft legislation did not address systemic sustainability risks created by AI, especially in the area\n",
      "of climate and environmental protection.10\n",
      "One of the major concerns raised was that the rules on prohibited and high-risk practices might\n",
      "prove ineffective in practice, because the risk assessment was proposed to be left to provider self-\n",
      "assessment. Veale and Zuiderveen Borgesius warned that most providers can arbitrarily classify\n",
      "most high-risk systems as adhering to the rules using self-assessment procedures alone. Smuha\n",
      "et al. recommended exploring whether certain high-risk systems would not benefit from a\n",
      "conformity assessment carried out by an independent entity prior to their deployment.\n",
      "5\n",
      "EPRS | European Parliamentary Research Service\n",
      "Biometrics regulation. A study commissioned by the European Parliament recommended, inter alia, to\n",
      "empower the Commission to adapt the list of prohibited AI practices periodically, under the supervision of the\n",
      "European Parliament, and the adoption of a more comprehensive list of 'restricted AI applications' (comprising\n",
      "real-time remote biometric identification without limitation for law enforcement purposes). Regulation of\n",
      "facial recognition technologies (FRTs) was one of the most contentious issues.11 The European Data Protection\n",
      "Supervisor (EDPS) and the European Data Protection Board (EDPB) called for a general ban on any uses of AI\n",
      "for the automated recognition of human features in publicly accessible spaces.\n",
      "Governance structure and enforcement and redress mechanisms\n",
      "Ebers et al. stressed that the AI act lacks effective enforcement structures, as the Commission\n",
      "proposed to leave the preliminary risk assessment, including the qualification as high-risk, to the\n",
      "providers' self-assessment. They also raised concerns about the excessive delegation of regulatory\n",
      "power to private European standardisation organisations (ESOs), due to the lack of democratic\n",
      "oversight, the impossibility for stakeholders (civil society organisations, consumer associations) to\n",
      "influence the development of standards, and the lack of judicial means to control them once they\n",
      "have been adopted. Instead, they recommended that the AI act codify a set of legally binding\n",
      "requirements for high-risk AI systems, which ESOs may specify through harmonised standards.\n",
      "Commentators regretted a crucial gap in the AI act – the lack of provision provide for individual\n",
      "enforcement rights. Ebers et al. stressed that individuals affected by AI systems and civil rights\n",
      "organisations have no right to complain to market surveillance authorities or to sue a provider or\n",
      "user for failure to comply with the requirements. Similarly, Veale and Zuiderveen Borgesius warned\n",
      "that, while some provisions of the draft legislation aim to impose obligations on AI systems users,\n",
      "no mechanism for complaint or judicial redress was available to them. Smuha et al. recommended\n",
      "amending the proposal to include, inter alia, an explicit right of redress for individuals and rights\n",
      "of consultation and participation for EU citizens regarding the decision to amend the list of high-\n",
      "risk systems in Annex III.\n",
      "It has also been stressed that the text proposed by the Commission lacked proper coordination\n",
      "mechanisms between authorities, in particular concerning cross-border infringement.\n",
      "Furthermore, guidance would be desirable on how to ensure compliance with transparency and\n",
      "information requirements, while simultaneously protecting intellectual property rights and trade\n",
      "secrets, not least to avoid diverging practices in the Member States.\n",
      "6\n",
      "Artificial intelligence act\n",
      "Legislative process\n",
      "Negotiation phase\n",
      "The Council adopted its common position in December 2022. In Parliament, the file was assigned\n",
      "jointly (under Rule 58) to the Committee on Internal Market and Consumer Protection (IMCO) and\n",
      "the Committee on Civil Liberties, Justice and Home Affairs (LIBE), with Brando Benifei (S&D, Italy)\n",
      "and Dragoş Tudorache, Renew, Romania) appointed as rapporteurs. Parliament adopted its\n",
      "negotiating position in June 2023, with substantial amendments to the Commission's text.\n",
      "Trilogue meetings took place in June, July, September, October and December 2023. Following\n",
      "protracted negotiations, the Council presidency and the European Parliament’s negotiators reached\n",
      "a provisional agreement on the AI act in December 2023. The regulation was adopted by Parliament\n",
      "in March 2024 and by the Council in May 2024. The AI act was formally signed on 13 June 2024,\n",
      "published in the Official Journal on 12 July, and entered into force on 1 August 2024.\n",
      "Final text\n",
      "Definitions\n",
      "The AI act enshrines in EU law a definition of AI systems aligned with the revised definition agreed\n",
      "by the OECD:\n",
      "An AI system is a machine-based system designed to operate with varying levels of autonomy\n",
      "and that may exhibit adaptiveness after deployment and that, for explicit or implicit objectives,\n",
      "infers, from the input it receives, how to generate outputs such as predictions, content,\n",
      "recommendations, or decisions that can influence physical or virtual environments.\n",
      "The definition is not intended to cover simpler traditional software systems or programming\n",
      "approaches, and the Commission has been tasked to develop guidelines on its application.\n",
      "The act also contains a definition of general purpose artificial intelligence (GPAI) models 'that are\n",
      "trained with a large amount of data using self-supervision at scale', that display 'significant\n",
      "generality' and are 'capable to competently perform a wide range of distinct tasks' and 'can be\n",
      "integrated into a variety of downstream systems or applications'. Furthermore, the AI act defines\n",
      "general-purpose AI systems as systems based on a GPAI model, which have the capability to serve\n",
      "a variety of purposes, both for direct use as well as for integration in other AI systems.\n",
      "Scope of application\n",
      "The AI act applies primarily to providers and deployers putting AI systems and GPAI models into\n",
      "service or placing them on the EU market and who have their place of establishment in or who are\n",
      "located in the EU, as well as to deployers or providers of AI systems that are established in a third\n",
      "country, when the output produced by their systems is used in the EU.12 However, AI systems placed\n",
      "on the market, put into service, or used by public and private entities for military, defence or\n",
      "national security purposes, are excluded from the scope. Similarly, the AI act will not apply to AI\n",
      "systems and models, including their output, which are specifically developed and put into service\n",
      "for the sole purpose of scientific research and development. Furthermore, as a matter of principle,\n",
      "the regulation does not apply prior to the systems and models being put into service or placed on\n",
      "the market (sandboxing rules may apply in this case).\n",
      "7\n",
      "EPRS | European Parliamentary Research Service\n",
      "EU AI act risk-based approach\n",
      "Data source: European Commission.\n",
      "The AI act adopts a risk-based approach and classifies AI systems into several risk categories, with\n",
      "different degrees of regulation applying.\n",
      " Prohibited AI practices. The final text prohibits a wider range of AI practices than\n",
      "originally proposed by the Commission because of their harmful impact:\n",
      " AI systems using subliminal or manipulative or deceptive techniques to distort\n",
      "people's or a group of people's behaviour and impair informed decision-\n",
      "making, leading to significant harm;\n",
      " AI systems exploiting vulnerabilities due to age, disability, or social or\n",
      "economic situations, causing significant harm;\n",
      " Biometric categorisation systems inferring race, political opinions, trade union\n",
      "membership, religious or philosophical beliefs, sex life, or sexual orientation\n",
      "(except for lawful labelling or filtering in law-enforcement purposes);\n",
      " AI systems evaluating or classifying individuals or groups based on social\n",
      "behaviour or personal characteristics, leading to detrimental or\n",
      "disproportionate treatment in unrelated contexts or unjustified or\n",
      "disproportionate to their behaviour;\n",
      " 'Real-time' remote biometric identification in public spaces for law\n",
      "enforcement (except for specific necessary objectives such as searching for\n",
      "victims of abduction, sexual exploitation or missing persons, preventing\n",
      "certain substantial and imminent threats to safety, or identifying suspects in\n",
      "serious crimes);\n",
      " AI systems assessing the risk of individuals committing criminal offences\n",
      "based solely on profiling or personality traits and characteristics (except when\n",
      "supporting human assessments based on objective, verifiable facts linked to\n",
      "a criminal activity);\n",
      "8\n",
      "Artificial intelligence act\n",
      " AI systems creating or expanding facial recognition databases through\n",
      "untargeted scraping from the internet or CCTV footage;\n",
      " AI systems inferring emotions in workplaces or educational institutions,\n",
      "except for medical or safety reasons.\n",
      " High-risk AI systems. The AI act identifies a number of use cases in which AI systems\n",
      "are to be considered high risk because they can potentially create an adverse impact\n",
      "on people's health, safety or their fundamental rights.\n",
      " The risk classification is based on the intended purpose of the AI system. The\n",
      "function performed by the AI system and the specific purpose and modalities\n",
      "for which the system is used are key to determine if an AI system is high-risk\n",
      "or not. High-risk AI systems can be safety components of products covered\n",
      "by sectoral EU law (e.g. medical devices) or AI systems that, as a matter of\n",
      "principle, are considered to be high risk when they are used in specific areas\n",
      "listed in an annex.13 The Commission is tasked with maintaining an EU\n",
      "database for the high-risk AI systems listed in this annex.\n",
      " A new test has been enshrined at the Parliament's request ('filter provision'),\n",
      "according to which AI systems will not be considered high risk if they do not\n",
      "pose a significant risk of harm to the health, safety or fundamental rights of\n",
      "natural persons.14 However, an AI system will always be considered high risk\n",
      "if the AI system performs profiling of natural persons.\n",
      " Providers of such high-risk AI systems will have to run a conformity\n",
      "assessment procedure before their products can be sold and used in the EU.\n",
      "They will need to comply with a range of requirements including for testing,\n",
      "data training and cybersecurity and, in some cases, will have to conduct a\n",
      "fundamental rights impact assessment to ensure their systems comply with\n",
      "EU law. The conformity assessment should be carried out either based on\n",
      "internal control (self-assessment) or with the involvement of a notified body\n",
      "(e.g. biometrics). Compliance with European harmonised standards to be\n",
      "developed will grant high-risk AI systems providers a presumption of\n",
      "conformity. After such AI systems are placed in the market, providers must\n",
      "implement post-market monitoring and take corrective actions if necessary.\n",
      " Transparency risk. Certain AI systems intended to interact with natural persons or to\n",
      "generate content may pose specific risks of impersonation or deception, irrespective\n",
      "of whether they qualify as high-risk AI systems or not. Such systems are subject to\n",
      "information and transparency requirements. Users must be made aware that they\n",
      "interact with chatbots. Deployers of AI systems that generate or manipulate image,\n",
      "audio or video content (i.e. deep fakes), must disclose that the content has been\n",
      "artificially generated or manipulated except in very limited cases (e.g. when it is used\n",
      "to prevent criminal offences). Providers of AI systems that generate large quantities\n",
      "of synthetic content must implement sufficiently reliable, interoperable, effective\n",
      "and robust techniques and methods (such as watermarks) to enable marking and\n",
      "detection that the output has been generated or manipulated by an AI system and not\n",
      "a human. Employers who deploy AI systems in the workplace must inform the\n",
      "workers and their representatives.\n",
      " Minimal risks. Systems presenting minimal risk for people (e.g. spam filters) will not\n",
      "be subject to further obligations beyond currently applicable legislation (e.g. GDPR).\n",
      " General-purpose AI (GPAI). The regulation provides specific rules for general-\n",
      "purpose AI models and for general-purpose AI models that pose systemic risks.\n",
      " GPAI system transparency requirements. All GPAI models will have to draw\n",
      "up and maintain up-to-date technical documentation and make information\n",
      "and documentation available to downstream providers of AI systems. All\n",
      "providers of GPAI models have to put a policy in place to respect Union\n",
      "copyright law, including through state-of-the-art technologies (e.g.\n",
      "9\n",
      "EPRS | European Parliamentary Research Service\n",
      "watermarking), to carry out lawful text- and data-mining exceptions as\n",
      "envisaged under the Copyright Directive. Furthermore, GPAIs must draw up\n",
      "and make publicly available a sufficiently detailed summary of the content\n",
      "used in training the GPAI models according to a template provided by the AI\n",
      "Office.15 Finally, if located outside the EU, they will have to appoint a\n",
      "representative in the EU. However, AI models made accessible under a free\n",
      "and open source will be exempt from some of the obligations (i.e. disclosure\n",
      "of technical documentation) given they have, in principle, positive effects on\n",
      "research, innovation and competition.16\n",
      " Systemic-risk GPAI obligations. GPAI models with 'high-impact\n",
      "capabilities' could pose a systemic risk and have a significant impact on the\n",
      "internal market, due to their reach and their actual or reasonably foreseeable\n",
      "negative effects (on public health, safety, public security, fundamental rights,\n",
      "or the society as a whole). GPAI providers must therefore notify the European\n",
      "Commission if their model is trained using a total computing power\n",
      "exceeding 10^25 FLOPs (i.e. floating-point operations per second). When this\n",
      "threshold is met, the presumption will be that the model is a GPAI model\n",
      "posing systemic risks.17 In addition to the requirements on transparency and\n",
      "copyright protection falling on all GPAI models, providers of systemic-risk\n",
      "GPAI models are required to constantly assess and mitigate the risks they\n",
      "pose and to ensure cybersecurity protection. That requires, inter alia, keeping\n",
      "track of, documenting and reporting serious incidents (e.g. violations of\n",
      "fundamental rights) and implementing corrective measures.\n",
      " Codes of practice and presumption of conformity. GPAI model providers\n",
      "will be able to rely on codes of practice to demonstrate compliance with the\n",
      "obligations set under the act. By means of implementing acts, the Commission\n",
      "may decide to approve a code of practice and give it a general validity within\n",
      "the EU, or alternatively, provide common rules for implementing the relevant\n",
      "obligations. Compliance with a European harmonised standard grants GPAI\n",
      "providers the presumption of conformity. Providers of GPAI models with\n",
      "systemic risks who do not adhere to an approved code of practice will be\n",
      "required to demonstrate adequate alternative means of compliance.\n",
      "Sandboxing and real-world testing\n",
      "The measures to support investment in AI systems have been strengthened. National authorities\n",
      "must establish at least one AI regulatory sandbox at national level to facilitate the development and\n",
      "testing of innovative AI systems under strict regulatory oversight.18 Such regulatory sandboxes\n",
      "provide for a controlled environment that fosters innovation and facilitates the development,\n",
      "training, testing and validation of innovative AI systems for a limited time before their placement on\n",
      "the market or entry into service. The AI regulatory sandbox must enable, where appropriate, testing\n",
      "of AI systems in real-world conditions outside of a laboratory for a limited period (subject to\n",
      "compliance with EU data protection law rules and principles). Furthermore, to accelerate the\n",
      "development and placing on the market of high-risk AI systems, providers or prospective providers\n",
      "of such systems may also test them in real-world conditions – even without participating in an AI\n",
      "regulatory sandbox – if they respect some guarantees and conditions (e.g. ask for specific consent,\n",
      "submit their real-world testing plan to the market surveillance authority).\n",
      "Enforcement and institutional setting\n",
      "The implementation of the act is the responsibility of a number of national and EU-level actors.\n",
      "Member States must establish or designate at least one market surveillance authority and at least\n",
      "one notifying authority to ensure the application and implementation of the act. Heavy fines fall on\n",
      "non-compliant entities.19 At EU level, a range of actors including the Commission, the AI Board, the\n",
      "10\n",
      "Artificial intelligence act\n",
      "AI Office, the EU standardisation bodies (CEN and CENELEC) and an advisory forum and scientific\n",
      "panel of independent experts support the implementation of the act. The EU AI Office was\n",
      "established to provide advice on the implementation of the new rules, in particular as regards GPAI\n",
      "models and to develop codes of practice to support the proper application of the AI act.\n",
      "'Entry into force' timelines\n",
      "Prohibited systems must be phased out within 6 months of the act's entry into force. The provisions\n",
      "concerning GPAI and penalties will apply 12 months after the act enters into force, and those\n",
      "concerning high-risk AI systems apply 24 months after entry into force (36 months after entry into\n",
      "force for AI systems covered by existing EU product legislation). The codes of practice envisaged\n",
      "must be ready, at the latest, nine months after the AI act enters into force. The implementation of\n",
      "the AI act requires a number of steps to be taken. In the coming months, the Commission is expected\n",
      "to issue various implementing and delegated acts, guidelines and codes of practices related to\n",
      "the act20 and to oversee the standardisation process required for implementing the obligations.21\n",
      "Parliament can exercise its scrutiny powers during this implementing phase, both through the\n",
      "reactivation of its Intergroup on Artificial Intelligence and Digital and by adopting formal objections\n",
      "to harmonised standards (Article 11 Regulation 1025/2012) and to Commission delegated or\n",
      "implementing acts (Rule 114 and Rule 115 of Parliament's Rules of Procedure).\n",
      "Latest issues in the policy debate\n",
      "Academics have raised several questions regarding the AI act's final text and the implementation\n",
      "challenges lying ahead. Hacker welcomes the final AI act but stresses, inter alia: that alignment with\n",
      "existing sectoral regulation is incomplete (which results in unnecessary and highly detrimental red\n",
      "tape); compliance costs will be substantial, especially for SMEs developing narrow AI models; the\n",
      "threshold of 10^25 FLOPs for a default categorisation of systemic risk models is too high; and\n",
      "European supervision and monitoring of remote biometric identification is needed to avoid the risk\n",
      "that some Member States circumvent the rules enshrined in the AI act.22 Kutterer argues the AI act's\n",
      "implementation will require a robust taxonomy setting out the correlation of risk classification and\n",
      "model capabilities and assessing the developments of open sources models.23 Helberger et al. call\n",
      "for the AI act to be complemented by an additional set of exercisable rights to protect citizens from\n",
      "AI-generated harm, with additional legislation to control the potential environmental impact of\n",
      "training AI models and protect workers' rights and to define further a set of requirements that\n",
      "research organisations must comply with to benefit from the research exemption.24\n",
      "Furthermore, some argue that the AI act does not go far enough in preventing and/or mitigating the\n",
      "specific risks associated with chatbots. Timely standardisation will be key to ensuring adequate\n",
      "implementation of the AI act, for instance, to ensure the robustness of high-risk AI systems and the\n",
      "watermarking of AI-generated content while, in the meantime, the EU is fostering the adoption of\n",
      "voluntary codes of conduct and of an AI pact to mitigate the potential downsides of generative AI.\n",
      "Some academics warn that that the standardisation and codification processes might not include\n",
      "representative groups of stakeholders nor adequately address fundamental rights impact\n",
      "assessment (FRIA).\n",
      "Ensuring international harmonisation of AI governance has become a key topic for policymakers.\n",
      "More cooperation on aligning AI governance between the EU and the US is seen as crucial for AI's\n",
      "democratic governance.25 Key questions such as setting common terminology and addressing dual-\n",
      "use and military AI applications have been raised in this respect.\n",
      "Finally, generative AI is seen as a disruptive technology that will likely mean amending EU laws and\n",
      "regulation. EU lawmakers are considering whether to legislate in other areas, such as on AI at the\n",
      "workplace, competition in generative AI (with much uncertainty regarding openness in generative\n",
      "AI), AI energy sustainability and, of course, intellectual property rights, with the possible revision of\n",
      "the Copyright Directive.\n",
      "11\n",
      "EPRS | European Parliamentary Research Service\n",
      "EUROPEAN PARLIAMENT SUPPORTING ANALYSIS\n",
      "EPRS, AI Repository, STOA Centre for Artificial Intelligence (C4AI), 2023.\n",
      "Wendehorst C. and Duller Y., Biometric Recognition and Behavioural Detection, Policy Department for\n",
      "Citizens' Rights and Constitutional Affairs, European Parliament, 2021.\n",
      "Dalli H., Artificial Intelligence Act: Initial Appraisal of the European Commission Impact Assessment,\n",
      "EPRS, European Parliament, 2021.\n",
      "Dumbrava C., Artificial intelligence at EU borders: Overview of applications and key issues, EPRS,\n",
      "European Parliament, 2021.\n",
      "Madiega T., Artificial intelligence act and regulatory sandboxes, EPRS, European Parliament, March 2022.\n",
      "Madiega T., General-purpose artificial intelligence, EPRS, European Parliament, March 2023.\n",
      "Madiega T., Generative AI and watermarking, EPRS, European Parliament, December 2023.\n",
      "Madiega T and Ilnicki R., AI investment: EU and global indicators, EPRS, European Parliament, 2024.\n",
      "Madiega T. A. and Mildebrath H. A., Regulating facial recognition in the EU, EPRS, European Parliament, 2021.\n",
      "OTHER SOURCES\n",
      "Artificial Intelligence Act, European Parliament, Legislative Observatory (OEIL).\n",
      "Hacker P., Comments on the final trilogue version of the AI act, 2024.\n",
      "Novelli C. et al., Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity, 2024.\n",
      "ENDNOTES\n",
      "1 See European Commission, Proposal for a regulation of the European Parliament and of the Council laying down\n",
      "harmonised rules on artificial intelligence (artificial intelligence act) 2021/0106(COD), Explanatory memorandum.\n",
      "2 See for instance, High-Level Expert Group, Ethics Guidelines for Trustworthy AI, 2019.\n",
      "3 See, inter alia, recommendations on intellectual property, criminal law, education, culture and audiovisual areas, and\n",
      "regarding civil and military AI uses.\n",
      "4 For an overview see H. Dalli, Artificial intelligence act, above.\n",
      "5 It was proposed to allow FRTs (i) for targeted search for potential victims of crime, including missing children; (ii) to\n",
      "prevent a specific, substantial and imminent threat to the life or physical safety of persons or of a terrorist attack; and\n",
      "(iii) for the detection, localisation, identification or prosecution of a perpetrator or individual suspected of a criminal\n",
      "offence referred to in the European Arrest Warrant Framework Decision.\n",
      "6 This section aims to provide a flavour of the debate and is not intended to be an exhaustive account of all different\n",
      "views on the proposal. Additional information can be found in publications listed under 'supporting analysis'.\n",
      "7 For an in-depth analysis of the proposals and recommendations for amendments see N. Smuha et al., How the EU can\n",
      "achieve legally trustworthy AI: A response to the European Commission's proposal for an artificial intelligence act,\n",
      "Elsevier, August 2021; M. Ebers et al, The European Commission’s proposal for an artificial intelligence act—A critical\n",
      "assessment by members of the Robotics and AI Law Society (RAILS), J, Vol. 4(4), pp. 589-603, October 2021.\n",
      "8 N. Smuha, et al., above, at pp. 14-15.;M. Veale and F. Zuiderveen Borgesius., Demystifying the draft EU AI act,\n",
      "Vol. 22(4), Computer Law Review International, July 2021.\n",
      "9 See M. Ebers et al., above.\n",
      "10 See V. Galaz et al., Artificial intelligence, systemic risks, and sustainability, Vol. 67, Technology in Society, 2021.\n",
      "11 For an overview, see T. Madiega and H. Mildebrath, Regulating facial recognition in the EU, 2021.\n",
      "12 The act applies to private organisations as well as to public authorities.\n",
      "13 The Annex refers to AI systems used in areas of critical infrastructures (e.g. road traffic), education and vocational\n",
      "training, employment worker management and access to self-employment, access to essential private and public\n",
      "services and benefits (e.g. creditworthiness evaluation), law enforcement, border control, administration of justice\n",
      "and democratic processes, biometric identification, categorisation and emotion recognition systems (outside the\n",
      "prohibited categories).\n",
      "14 An AI system will not be considered as high-risk if one or more of the following criteria are fulfilled: (i) the AI system\n",
      "is intended to perform a narrow procedural task; (ii) the AI system is intended to improve the result of a previously\n",
      "completed human activity; (iii) the AI system is intended to detect decision-making patterns or deviations from prior\n",
      "decision-making patterns and is not meant to replace or influence the previously completed human assessment\n",
      "without proper human review; or (iv) the AI system is intended to perform a preparatory task to an assessment\n",
      "relevant for the purpose of the use cases listed in Annex III.\n",
      "12\n",
      "Artificial intelligence act\n",
      "15 Established by European Commission decision in January 2024 the AI Office enters into force in February 2024.\n",
      "16 Furthermore, open-source models must comply with the AI act when they are integrated into prohibited AI practices\n",
      "or into high-risk systems and when they are considered to present systemic risk.\n",
      "17 FLOPs, or Floating-Point Operations Per Second, measure a computer's processing speed. The threshold should be\n",
      "adjusted over time to reflect technological and industrial changes. Moreover, the Commission is entitled to take\n",
      "individual decisions designating a GPAI model posing systemic risk if it is found that such model has capabilities or\n",
      "impact equivalent to those captured by the FLOP threshold on the basis of an overall assessment of criteria (e.g.\n",
      "quality or size of the training data set, number of business and end users, degree of autonomy and scalability). In the\n",
      "US, President Biden's AI executive order set 10^26 FLOPs as the threshold for AI models that need to be reported to\n",
      "the government with details of their training, capabilities and security.\n",
      "18 Additional AI regulatory sandboxes at regional or local levels or jointly with other Member States' competent\n",
      "authorities may also be established. The European Data Protection Supervisor may also establish an AI regulatory\n",
      "sandbox for the EU institutions, bodies and agencies.\n",
      "19 For instance, up to €35 million or 7 % of the total worldwide annual turnover of the preceding financial year (whichever\n",
      "is higher) for infringements on prohibited practices or non-compliance related to requirements on data.\n",
      "20 Implementing acts must be adopted by the Commission to establish common specifications for requirements for\n",
      "high-risk systems, to approve codes of practice on generated or manipulated content and to specify common rules\n",
      "for implementation if such codes of practice are deemed not adequate. Delegated acts will need to be adopted to\n",
      "identify conditions for AI systems to not be considered high-risk and to specify and update criteria of GPAI posing\n",
      "systemic risk, inter alia. The AI Office will have to draw up the codes of practice for GPAI providers.\n",
      "21 The Commission mandated the European Standardisation Organisations (CEN-CENELEC) to deliver a series of\n",
      "European standards to implement the AI act by January 2025.\n",
      "22 See P. Hacker, Comments on the final trilogue version of the AI act, 2024.\n",
      "23 See C. Kutterer, Regulating foundation models in the AI act: from \"high\" to \"systemic\" risk, 2024.\n",
      "24 See N. Helberger et al., The Amsterdam Paper: Recommendations for the technical finalisation of the regulation of\n",
      "GPAI in the AI act, 2024. See also, P. Chavez, An AI challenge: Balancing open and closed systems, 2023.\n",
      "25 See A. Engler, The EU and U.S. diverge on AI regulation: A transatlantic comparison and steps to alignment, 2023.\n",
      "DISCLAIMER AND COPYRIGHT\n",
      "This document is prepared for, and addressed to, the Members and staff of the European Parliament as\n",
      "background material to assist them in their parliamentary work. The content of the document is the sole\n",
      "responsibility of its author(s) and any opinions expressed herein should not be taken to represent an official\n",
      "position of the Parliament.\n",
      "Reproduction and translation for non-commercial purposes are authorised, provided the source is\n",
      "acknowledged and the European Parliament is given prior notice and sent a copy.\n",
      "© European Union, 2024.\n",
      "eprs@ep.europa.eu (contact)\n",
      "www.eprs.ep.parl.union.eu (intranet)\n",
      "www.europarl.europa.eu/thinktank (internet)\n",
      "http://epthinktank.eu (blog)\n",
      "Fourth edition. 'EU Legislation in Progress' briefings are updated at key stages of the legislative procedure.\n",
      "13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "# open the PDF\n",
    "with pdfplumber.open('EU AI Act.pdf') as pdf:\n",
    "    text = ''\n",
    "    # iterate through each page\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text() + '\\n'\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3e7933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.splitlines()\n",
    "\n",
    "title = lines[:3]\n",
    "text = lines[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22810ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    {\n",
    "        \"title\": title,\n",
    "        \"text\": text\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b3157bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import hnswlib\n",
    "from typing import List, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce5c61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorstore:\n",
    "    \"\"\"\n",
    "    A class representing a collection of documents indexed into a vectorstore.\n",
    "\n",
    "    Parameters:\n",
    "    raw_documents (list): A list of dictionaries representing the sources of the raw documents. Each dictionary should have 'title' and 'url' keys.\n",
    "\n",
    "    Attributes:\n",
    "    raw_documents (list): A list of dictionaries representing the raw documents.\n",
    "    docs (list): A list of dictionaries representing the chunked documents, with 'title', 'text', and 'url' keys.\n",
    "    docs_embs (list): A list of the associated embeddings for the document chunks.\n",
    "    docs_len (int): The number of document chunks in the collection.\n",
    "    idx (hnswlib.Index): The index used for document retrieval.\n",
    "\n",
    "    Methods:\n",
    "    load_and_chunk(): Loads the data from the sources and partitions the HTML content into chunks.\n",
    "    embed(): Embeds the document chunks using the Cohere API.\n",
    "    index(): Indexes the document chunks for efficient retrieval.\n",
    "    retrieve(): Retrieves document chunks based on the given query.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, documents: List[Dict[str, str]]):\n",
    "        self.documents = documents\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load_and_chunk()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "\n",
    "\n",
    "    def load_and_chunk(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the pre-extracted text documents and stores them as chunks.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for raw_document in self.documents:\n",
    "            title = document[\"title\"]\n",
    "            text = document[\"text\"]\n",
    "\n",
    "            # Assuming you want to chunk by paragraphs or a similar method\n",
    "            chunks = self.chunk_text(text)\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                self.docs.append(\n",
    "                    {\n",
    "                        \"title\": title,\n",
    "                        \"text\": str(chunk)\n",
    "                    }\n",
    "                )\n",
    "        print(f\"Loaded {len(self.docs)} document chunks.\")\n",
    "\n",
    "    def chunk_text(self, text: str, max_chunk_size: int = 500) -> list:\n",
    "        \"\"\"\n",
    "        Splits the text into chunks of a maximum size.\n",
    "        \"\"\"\n",
    "        # You can implement a more sophisticated chunking logic here\n",
    "        return [text[i:i + max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
    "\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the document chunks using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding document chunks...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the document chunks for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing document chunks...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} document chunks.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves document chunks based on the given query.\n",
    "\n",
    "        Parameters:\n",
    "        query (str): The query to retrieve document chunks for.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved document chunks, with 'title', 'text', and 'url' keys.\n",
    "        \"\"\"\n",
    "\n",
    "        # Dense retrieval\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "        \n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "\n",
    "        # Reranking\n",
    "        rank_fields = [\"title\", \"text\"] # We'll use the title and text fields for reranking\n",
    "\n",
    "        docs_to_rerank = [self.docs[doc_id] for doc_id in doc_ids]\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v3.0\",\n",
    "            rank_fields=rank_fields\n",
    "        )\n",
    "\n",
    "        doc_ids_reranked = [doc_ids[result.index] for result in rerank_results.results]\n",
    "\n",
    "        docs_retrieved = []\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            docs_retrieved.append(\n",
    "                {\n",
    "                    \"title\": self.docs[doc_id][\"title\"],\n",
    "                    \"text\": self.docs[doc_id][\"text\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return docs_retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba6e2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Loaded 96 document chunks.\n",
      "Embedding document chunks...\n",
      "Indexing document chunks...\n",
      "Indexing complete with 96 document chunks.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Vectorstore class with the given sources\n",
    "vectorstore = Vectorstore(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8de7d7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'BRIEFING\\nEU Legislation in Progress\\nArtificial intelligence act',\n",
       "  'text': 'ion of\\nconformity with the draft AI act requirements.\\nThird, AI systems presenting limited risk, such as systems that interact with humans (i.e. chatbots),\\nemotion recognition systems, biometric categorisation systems, and AI systems that generate or\\nmanipulate image, audio or video content (i.e. deepfakes), would be subject to a limited set of\\ntransparency obligations.\\nFinally, all other AI systems presenting only low or minimal risk could be developed and used in the\\nEU without conforming to a'},\n",
       " {'title': 'BRIEFING\\nEU Legislation in Progress\\nArtificial intelligence act',\n",
       "  'text': ' for instance, to ensure the robustness of high-risk AI systems and the\\nwatermarking of AI-generated content while, in the meantime, the EU is fostering the adoption of\\nvoluntary codes of conduct and of an AI pact to mitigate the potential downsides of generative AI.\\nSome academics warn that that the standardisation and codification processes might not include\\nrepresentative groups of stakeholders nor adequately address fundamental rights impact\\nassessment (FRIA).\\nEnsuring international harmonis'},\n",
       " {'title': 'BRIEFING\\nEU Legislation in Progress\\nArtificial intelligence act',\n",
       "  'text': \"nd may lead to legal uncertainty, especially for some\\nsystems that would not qualify as AI systems under the draft text, while their use may have an\\nadverse impact on fundamental rights.8 To address this issue, the authors proposed to broaden the\\nlegislation's scope to include explicitly all computational systems used in the identified high-risk\\ndomains, regardless of whether they are considered to be AI. Ebers et al. consider that the scope of\\n'AI systems' was overly broad, which may lead to le\"}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.retrieve(\"Prompting by giving examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecad997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chatbot(message, chat_history=None):\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    # Generate search queries, if any        \n",
    "    response = co.chat(message=message,\n",
    "                        model=\"command-r-plus\",\n",
    "                        search_queries_only=True,\n",
    "                        chat_history=chat_history)\n",
    "    \n",
    "    search_queries = []\n",
    "    for query in response.search_queries:\n",
    "        search_queries.append(query.text)\n",
    "\n",
    "    # If there are search queries, retrieve the documents\n",
    "    if search_queries:\n",
    "        print(\"Retrieving information...\", end=\"\")\n",
    "\n",
    "        # Retrieve document chunks for each query\n",
    "        documents = []\n",
    "        for query in search_queries:\n",
    "            documents.extend(vectorstore.retrieve(query))\n",
    "\n",
    "        # Use document chunks to respond\n",
    "        response = co.chat_stream(\n",
    "            message=message,\n",
    "            model=\"command-r-plus\",\n",
    "            documents=documents,\n",
    "            chat_history=chat_history,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        response = co.chat_stream(\n",
    "            message=message,\n",
    "            model=\"command-r-plus\",\n",
    "            chat_history=chat_history,\n",
    "        )\n",
    "        \n",
    "    # Print the chatbot response, citations, and documents\n",
    "    chatbot_response = \"\"\n",
    "    print(\"\\nChatbot:\")\n",
    "\n",
    "    for event in response:\n",
    "        if event.event_type == \"text-generation\":\n",
    "            print(event.text, end=\"\")\n",
    "            chatbot_response += event.text\n",
    "        if event.event_type == \"stream-end\":\n",
    "            if event.response.citations:\n",
    "                print(\"\\n\\nCITATIONS:\")\n",
    "                for citation in event.response.citations:\n",
    "                    print(citation)\n",
    "            if event.response.documents:\n",
    "                print(\"\\nCITED DOCUMENTS:\")\n",
    "                for document in event.response.documents:\n",
    "                    print(document)\n",
    "            # Update the chat history for the next turn\n",
    "            chat_history = event.response.chat_history\n",
    "\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee33c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide context to the LLM about our role\n",
    "context = \"We are a technology consulting company with global clients. It is important for our company and the clients of our company to stay within regulations of the strictest AI act, the EU AI Act. \"\n",
    "\n",
    "# pass case scenario to the LLM with context\n",
    "message = context + \"A client in the healthcare industry has approached our tech consulting company with a proposal for an AI doctor that can use a patient's information to detect health risk and diagnoses. How much risk does this project have according to the EU AI Act? Please provide quotes and citations from the document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bc5180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot:\n",
      "Of course! I am here to help. Please go ahead with your question and I will do my best to assist you."
     ]
    }
   ],
   "source": [
    "# Turn # 1\n",
    "chat_history = run_chatbot(\"Hello, I have a question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1ac6224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving information...\n",
      "Chatbot:\n",
      "The EU AI Act, signed in June 2024, adopts a risk-based approach to the use and supply of AI systems in the EU. It identifies several use cases where AI systems are considered high-risk because they can potentially adversely affect people's health, safety, or fundamental rights. \n",
      "\n",
      "The proposal for an AI doctor that can use a patient's information to detect health risks and make diagnoses would likely be considered high-risk according to the EU AI Act. This is because the Act specifically mentions that high-risk AI systems can include medical devices. \n",
      "\n",
      "> High-risk AI systems can be safety components of products covered by sectoral EU law (e.g. medical devices) or AI systems that, as a matter of principle, are considered to be high risk when they are used in specific areas listed in an annex.\n",
      "\n",
      "Furthermore, the Act states that AI systems that perform profiling of natural persons will always be considered high-risk:\n",
      "\n",
      "> an AI system will always be considered high risk if the AI system performs profiling of natural persons.\n",
      "\n",
      "Providers of high-risk AI systems must run a conformity assessment procedure before their products can be sold and used in the EU.\n",
      "\n",
      "CITATIONS:\n",
      "start=4 end=34 text='EU AI Act, signed in June 2024' document_ids=['doc_3']\n",
      "start=45 end=64 text='risk-based approach' document_ids=['doc_3', 'doc_5']\n",
      "start=72 end=111 text='use and supply of AI systems in the EU.' document_ids=['doc_3']\n",
      "start=126 end=143 text='several use cases' document_ids=['doc_0', 'doc_5']\n",
      "start=176 end=185 text='high-risk' document_ids=['doc_0', 'doc_1', 'doc_2', 'doc_3']\n",
      "start=215 end=279 text=\"adversely affect people's health, safety, or fundamental rights.\" document_ids=['doc_0', 'doc_2']\n",
      "start=540 end=556 text='medical devices.' document_ids=['doc_1']\n",
      "start=561 end=802 text='High-risk AI systems can be safety components of products covered by sectoral EU law (e.g. medical devices) or AI systems that, as a matter of principle, are considered to be high risk when they are used in specific areas listed in an annex.' document_ids=['doc_1']\n",
      "start=861 end=889 text='profiling of natural persons' document_ids=['doc_2']\n",
      "start=930 end=1034 text='an AI system will always be considered high risk if the AI system performs profiling of natural persons.' document_ids=['doc_2']\n",
      "start=1036 end=1166 text='Providers of high-risk AI systems must run a conformity assessment procedure before their products can be sold and used in the EU.' document_ids=['doc_2']\n",
      "\n",
      "CITED DOCUMENTS:\n",
      "{'id': 'doc_3', 'text': \"OVERVIEW\\nEuropean Union lawmakers signed the artificial intelligence (AI) act in June 2024. The AI act, the first\\nbinding worldwide horizontal regulation on AI, sets a common framework for the use and supply of\\nAI systems in the EU.\\nThe new act offers a classification for AI systems with different requirements and obligations tailored\\nto a 'risk-based approach'. Some AI systems presenting 'unacceptable' risks are prohibited. A wide\\nrange of 'high-risk' AI systems that can have a detrimental impa\", 'title': 'BRIEFING\\nEU Legislation in Progress\\nArtificial intelligence act'}\n",
      "{'id': 'doc_5', 'text': ' and models being put into service or placed on\\nthe market (sandboxing rules may apply in this case).\\n7\\nEPRS | European Parliamentary Research Service\\nEU AI act risk-based approach\\nData source: European Commission.\\nThe AI act adopts a risk-based approach and classifies AI systems into several risk categories, with\\ndifferent degrees of regulation applying.\\n\\uf0d8 Prohibited AI practices. The final text prohibits a wider range of AI practices than\\noriginally proposed by the Commission because of their ', 'title': 'BRIEFING\\nEU Legislation in Progress\\nArtificial intelligence act'}\n",
      "{'id': 'doc_0', 'text': \"ing from the internet or CCTV footage;\\n\\uf0d8 AI systems inferring emotions in workplaces or educational institutions,\\nexcept for medical or safety reasons.\\n\\uf0d8 High-risk AI systems. The AI act identifies a number of use cases in which AI systems\\nare to be considered high risk because they can potentially create an adverse impact\\non people's health, safety or their fundamental rights.\\n\\uf0d8 The risk classification is based on the intended purpose of the AI system. The\\nfunction performed by the AI system an\", 'title': 'BRIEFING\\nEU Legislation in Progress\\nArtificial intelligence act'}\n",
      "{'id': 'doc_1', 'text': 'd the specific purpose and modalities\\nfor which the system is used are key to determine if an AI system is high-risk\\nor not. High-risk AI systems can be safety components of products covered\\nby sectoral EU law (e.g. medical devices) or AI systems that, as a matter of\\nprinciple, are considered to be high risk when they are used in specific areas\\nlisted in an annex.13 The Commission is tasked with maintaining an EU\\ndatabase for the high-risk AI systems listed in this annex.\\n\\uf0d8 A new test has been e', 'title': 'BRIEFING\\nEU Legislation in Progress\\nArtificial intelligence act'}\n",
      "{'id': 'doc_2', 'text': \"nshrined at the Parliament's request ('filter provision'),\\naccording to which AI systems will not be considered high risk if they do not\\npose a significant risk of harm to the health, safety or fundamental rights of\\nnatural persons.14 However, an AI system will always be considered high risk\\nif the AI system performs profiling of natural persons.\\n\\uf0d8 Providers of such high-risk AI systems will have to run a conformity\\nassessment procedure before their products can be sold and used in the EU.\\nThey \", 'title': 'BRIEFING\\nEU Legislation in Progress\\nArtificial intelligence act'}\n"
     ]
    }
   ],
   "source": [
    "# Turn # 2\n",
    "chat_history = run_chatbot(message, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12216bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "feb542bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnprocessableEntityError",
     "evalue": "status_code: 422, body: data=None message='invalid request: field title must be a string. For proper usage, please refer to https://docs.cohere.com/reference/chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnprocessableEntityError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m citations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m cited_documents \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mevent_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(event\u001b[38;5;241m.\u001b[39mtext, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\cohere\\base_client.py:632\u001b[0m, in \u001b[0;36mBaseCohere.chat_stream\u001b[1;34m(self, message, accepts, model, preamble, chat_history, conversation_id, prompt_truncation, connectors, search_queries_only, documents, citation_quality, temperature, max_tokens, max_input_tokens, k, p, seed, stop_sequences, frequency_penalty, presence_penalty, raw_prompting, return_prompt, tools, tool_results, force_single_step, response_format, safety_mode, request_options)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[0;32m    623\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(\n\u001b[0;32m    624\u001b[0m             typing\u001b[38;5;241m.\u001b[39mOptional[typing\u001b[38;5;241m.\u001b[39mAny],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    629\u001b[0m         )\n\u001b[0;32m    630\u001b[0m     )\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m422\u001b[39m:\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnprocessableEntityError(\n\u001b[0;32m    633\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(\n\u001b[0;32m    634\u001b[0m             UnprocessableEntityErrorBody,\n\u001b[0;32m    635\u001b[0m             construct_type(\n\u001b[0;32m    636\u001b[0m                 type_\u001b[38;5;241m=\u001b[39mUnprocessableEntityErrorBody,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    637\u001b[0m                 object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[0;32m    638\u001b[0m             ),\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     )\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TooManyRequestsError(\n\u001b[0;32m    643\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(\n\u001b[0;32m    644\u001b[0m             TooManyRequestsErrorBody,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m         )\n\u001b[0;32m    650\u001b[0m     )\n",
      "\u001b[1;31mUnprocessableEntityError\u001b[0m: status_code: 422, body: data=None message='invalid request: field title must be a string. For proper usage, please refer to https://docs.cohere.com/reference/chat'"
     ]
    }
   ],
   "source": [
    "# provide context to the LLM about our role\n",
    "context = \"We are a technology consulting company with global clients. It is important for our company and the clients of our company to stay within regulations of the strictest AI act, the EU AI Act. \"\n",
    "\n",
    "# pass case scenario to the LLM with context\n",
    "message = context + \"A client in the healthcare industry has approached our tech consulting company with a proposal for an AI doctor that can use a patient's information to detect health risk and diagnoses. How much risk does this project have according to the EU AI Act? Please provide quotes and citations from the document.\"\n",
    "\n",
    "# generate the response\n",
    "response = co.chat_stream(message=message,\n",
    "                          model=\"command-r-plus\",\n",
    "                          documents=documents)\n",
    "\n",
    "# display the response\n",
    "citations = []\n",
    "cited_documents = []\n",
    "\n",
    "for event in response:\n",
    "    if event.event_type == \"text-generation\":\n",
    "        print(event.text, end=\"\")\n",
    "    elif event.event_type == \"citation-generation\":\n",
    "        citations.extend(event.citations)\n",
    "    elif event.event_type == \"stream-end\":\n",
    "      cited_documents = event.response.documents\n",
    "\n",
    "# display the citations and source documents\n",
    "if citations:\n",
    "  print(\"\\n\\nCITATIONS:\")\n",
    "  for citation in citations:\n",
    "    print(citation)\n",
    "\n",
    "  print(\"\\nDOCUMENTS:\")\n",
    "  for document in cited_documents:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87392646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
